<!DOCTYPE html>
<html>

<?php 
$title = "GSoC 2018和Flux模型动物园的语音识别：结论";
$keywords = "GSoC 2018和Flux模型动物园的语音识别：结论";
$description = "";
$active_menu = "blog";
require_once('../_common/head.html'); ?>

<body>

  <?php require_once('../_common/nav.html'); ?>

  <br><br>

  <div class="container">

    <div class="row">
      <div class="col-12 col-lg-8 offset-lg-2">
        <h1></h1>

        <div id="blogpost">
          <h1>GSoC 2018和Flux模型动物园的语音识别：结论</h1>

          <p class="metadata">
            <span class="timestamp">2018年8月14日</span> | <span class="author"><a href="https://github.com/maetshju">Matthew C. Kelley</a></span>
          </p>

          <p>
            在这里，我们处于Google Summer of Code 2018的另一端。这是一次具有挑战性和教育性的和无可替代的一种体验，我很感谢Julia社区，
            特别是我的导师<a href="https://github.com/mikeinnes">@MikeInnes</a>，感谢他支持我。我学到了很多东西，比以前更熟练掌握神经网络，
            我学会了如何进行基本的GPU编程，这对我的学术生涯非常有用。
            </p>

          <p>
            本博文的其余部分将总结我的项目和我整个夏天所做的工作，然后记录自己还有哪些待完成的工作，
            最后简要介绍如何运行我编写的代码来试用它并且能够为你自己所用。
          </p>

          <h1 id="have-you-ever-wanted-your-computer-to-understand-speech">你曾经想过让你的电脑听得懂你的话吗？</h1>

          <p>语音识别目前在许多科技公司中流行。 例如，谷歌(Google Home)和亚马逊(Alexa)分别大力推动他们的独立语音助手产品。如果没有功能性语音识别，这些产品将胎死腹中</p>

          <p>
            不幸的是，对于许多研究人员和潜在的语音识别爱好者来说，
            语音识别系统的文档似乎没有图像识别系统那么多。
            这个2018年谷歌夏季代码项目的目标是将一些语音识别模型贡献给<a href="https://github.com/FluxML/model-zoo">Flux模型动物园</a>，这样就会有一些免费的模型供其他人使用。
          </p>

          <p>
            在项目结束时，训练出了两种不同的模型。第一种是使用称为连接时间分类（CTC）的损失函数的一种相当新的方法（Graves等，2006）。可实践的模型来自Zhang等人。（2017），它使用卷积层来学习数据中的时间依赖性，这与使用复发层的CTC损失的传统方法不同。这是一个层数非常深的网络，作者认为它允许它学习时间依赖性。
          </p>

          <p>第二个网络是一种旧式的框架识别模型，灵感来自Graves＆Schmidhuber（2005）。它预测通过网络传递的每个音频块的类，并使用分类交叉熵作为其丢失函数。它将作为CTC网络的基准进行比较。</p>

          <p>对于那些不熟悉语音识别系统的人来说，从声学到电话标签的映射仍然是一个未解决的问题，因为没有人仅仅在音频帧的标签识别上达到95％或99％的准确度 因此，报告的准确度似乎并不令人满意（CTC网络当然也是如此），但这也是语音识别系统的长期的诟病。</p>

          <h1 id="results-of-the-ctc-network">CTC网络的结果</h1>

          <p>
            一旦分解为步骤，该项目的主要任务是实现网络架构并在Flux和Julia中实现CTC损失功能。这两项任务的朴素实现变得简单，但性能不适合能够训练网络。回想起来，提高网络的计算效率并不困难，因为它只需要在Flux的<code class="highlighter-rouge">Chain</code>函数中添加一个<code class="highlighter-rouge">reshape</code>调用来将卷积层连接到完全连接的层。
          </p>

          <p>
            真正的试验是让CTC损失正确有效地运行。在最终决定使用百度的CTC GPU实现的简单端口<a href="https://github.com/baidu-research/warp-ctc">warp-ctc</a>之前，我起初在讨论CPU实现。这是我第一次尝试编写GPU内核，我学到了很多东西。但是在完成移植内核几周后，我有一个有关丢失功能的GPU实现。或者我想。我花了几周时间尝试使用各种优化器进行不同的训练配置和例程，但是我无法让网络输出超出空白语音标签类别的预测。我在<a href="https://maetshju.github.io/update3.html">几篇</a>博文中写过<a href="https://maetshju.github.io/update4.html">这篇</a>文章。
          </p>

          <p>
            事实证明，我的实现中存在轻微的错误，这些错误源自百度的warp-ctc库本身。正如我在撰写<a href="https://maetshju.github.io/update5.html">关于此错误的博客文章</a>时所做的那样，我不知道在其他百度代码的上下文中是否实际上是一个错误。但是，在修复错误后，我发现代码中的损失显着减少。具体来说，有一段代码被评估为：
          </p>

          <math xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>β</mi>
            <mo>(</mo>
            <mi>t</mi>
            <mo>,</mo>
            <mi>u</mi>
            <mo>)</mo>
            <mo>=</mo>
            <msubsup>
              <mi>y</mi>
              <mrow>
                <mi>l</mi>
                <msub>
                  <mo>'</mo>
                  <mi>u</mi>
                </msub>
              </mrow>
              <mrow>
                <mi>t</mi>
                <mo>+</mo>
                <mn>1</mn>
              </mrow>
            </msubsup>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mi>u</mi>
              </mrow>
              <mrow>
                <mi>g</mi>
                <mo>(</mo>
                <mi>u</mi>
                <mo>)</mo>
              </mrow>
            </munderover>
            <mi>β</mi>
            <mo>(</mo>
            <mi>t</mi>
            <mo>+</mo>
            <mn>1</mn>
            <mo>,</mo>
            <mi>i</mi>
            <mo>)</mo>
            <mo> </mo>
            <mo>,</mo>
          </math>

          <p>我们什么时候应该计算：</p>

          <math xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>β</mi>
            <mo>(</mo>
            <mi>t</mi>
            <mo>,</mo>
            <mi>u</mi>
            <mo>)</mo>
            <mo>=</mo>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mi>u</mi>
              </mrow>
              <mrow>
                <mi>g</mi>
                <mo>(</mo>
                <mi>u</mi>
                <mo>)</mo>
              </mrow>
            </munderover>
            <mi>β</mi>
            <mo>(</mo>
            <mi>t</mi>
            <mo>+</mo>
            <mn>1</mn>
            <mo>,</mo>
            <mi>i</mi>
            <mo>)</mo>
            <msubsup>
              <mi>y</mi>
              <mrow>
                <mi>l</mi>
                <msub>
                  <mo>'</mo>
                  <mi>i</mi>
                </msub>
              </mrow>
              <mrow>
                <mi>t</mi>
                <mo>+</mo>
                <mn>1</mn>
              </mrow>
            </msubsup>
            <mo> </mo>
            <mo>.</mo>
          </math>

          <p>
            有关这方面的更多信息，请参阅<a href="https://maetshju.github.io/update5.html">我之前的帖子</a>。进行此更改会导致网络最终为每个数据时间步输出标签预测。标签不一定总是有意义，但它至少是在做出预测。
          </p>

          <p>这就是语音识别系统现在所在的位置。网络体系结构应该正确地实现，而损失函数现在看来是正确运行的。也就是说，网络在一定程度上是运行和学习的。您可以根据下面的示例输出来评估它的学习效果：</p>

          <p><strong>文本转录</strong></p>

          <blockquote>
            <p>这次潜水的原因现在看起来很愚蠢。</p>
          </blockquote>

          <p><strong>目标语音的顺序</strong></p>

          <blockquote>
            <p>h# dh ix r iy z ax n z f axr dh ih s dcl d ay v s iy m dcl d f uw l ix sh epi n aw h#</p>
          </blockquote>

          <p><strong>预测语音的顺序</strong></p>

          <blockquote>
            <p>h# pau w iy bcl r iy ux z bcl b iy bcl b uw z ay n pcl p z iy n dcl d v w iy er h#</p>
          </blockquote>

          <p>与目标相比，这一预测的电话错误率约为84%。这个模型是。显然还没有准备好被添加到模型动物园，因为它的表现不佳。</p>

          <h1 id="results-of-the-framewise-network">框架式网络的结果</h1>

          <p>
            framewise网络的主要任务是找到如何有效地训练网络。在识别结果方面，framewise网络比CTC网络好得多。在仅仅两个训练时期，它在测试集上达到约<strong>53.5％的标签预测准确度</strong>。 
            显然，网络应该训练的时间比Graves＆Schmidhuber的性能要长，但值得注意的是，即使在这么早的阶段它也要胜过CTC网络。该网络与CTC网络性能之间的差异令人震惊。尽管CTC网络的任务更加困难，但令人惊讶的是，即使并不令人惊讶，允许网络利用训练数据中的额外信息也可以改善这种程度。
          </p>

          <h1 id="what-remains-to-be-done">剩下要做的事</h1>

          <p>
            <strong>framewise网络用于完成所有意图和目的</strong>。它应该适合作为演示网络的目的，它非常接近Graves报告的网络性能。如果希望它运行得更快，可以使用批处理并在GPU上运行。
          </p>

          <p>
            <strong>对于CTC网络，需要调查为什么它没有学习如何执行张等人的程度。
            报告。</strong>下图是从第一次运行具有上述校正损失功能的网络开始的训练和验证损失随时间变化的曲线图。
            优化器是AMSGrad，学习率为$ 10 ^ { - 4} $。 
            这是我在其他优化器和训练配置中看到的行为的特征，无论它们是新的开始还是继续以前的训练。
          </p>

          <p><img src="./static/images/ctcloss.png" alt="CTC随时间流失。注意，y轴以对数标度表示。"></p>

          <p>
            即使训练损失继续减少，验证损失仍处于次优水平。在这个时刻我不确定这种行为的原因是什么，因为我已尽力尽可能接近张等人给出的实施细节。
            我不相信它在CTC功能中，因为我已经对手工解决方案多次测试了CTC损失功能，并且看到它产生了正确的结果; 
            类似地，它提供的梯度允许网络将一个训练示例拟合到接近零的损失水平，因此看起来该功能似乎提供足够可靠的损耗信号以最小化损失。
            我可能需要调查反向传播的方式，以查看批次中的损失值是否正确组合。
          </p>

          <h1 id="running-the-models">运行模型</h1>

          <p>
            运行模型的训练过程应该很简单。确保已安装WAV，Flux，CuArrays，JLD和BSON软件包。同样，安装<a href="https://github.com/maetshju/MFCC.jl">我用MFCC包装的叉子</a>（只更新一行以使功能在Julia 0.6上运行）。首先克隆项目的Git存储库：
          </p>

          <blockquote>
            <p>$ git clone https://github.com/maetshju/gsoc2018.git</p>
          </blockquote>

          <p>
            用户需要从Linguistic Data Consortium下载TIMIT语音语料库，正如我在之前<a href="https://maetshju.github.io/speech-features.html">博客文章的第一部分</a>中所讨论的那样。
          </p>

          <h2 id="ctc-model">CTC模型</h2>

          <p>
            导航到<code class="highlighter-rouge">speech-cnn</code>文件夹。要从TIMIT语料库中提取数据，请使用<code class="highlighter-rouge">00-data.jl</code>脚本。有关此脚本的更多信息可以在专门的<a href="https://maetshju.github.io/speech-features.html">博客文章</a>中找到。
          </p>

          <blockquote>
            <p>$ julia 00-data.jl</p>
          </blockquote>

          <p>
            现在，要训练网络，请运行<code class="highlighter-rouge">01-speech-cnn.jl</code>脚本。如果您下载了这些文件，请确保已从数据文件夹中删除了<code class="highlighter-rouge">README.md</code>文件。
          </p>

          <blockquote>
            <p>$ julia 01-speech-cnn.jl</p>
          </blockquote>

          <p>
            请注意，基本上有必要使用GPU来训练网络，因为训练过程仅在CPU上非常慢。此外，该脚本调用了CTC算法的GPU实现，如果没有GPU，它将失败。
            脚本可能需要一天才能运行，所以稍后再回过头来。 脚本完成后，应该训练模型并准备好进行预测。
          </p>

          <h2 id="framewise-model">Framewise模型</h2>

          <p>
            导航到<code class="highlighter-rouge">speech-blstm</code>文件夹。要从TIMIT语料库中提取数据，请使用<code class="highlighter-rouge">00-data.jl</code>脚本。
          </p>

          <blockquote>
            <p>$ julia 00-data.jl</p>
          </blockquote>

          <p>
            现在，要训练网络，请运行<code class="highlighter-rouge">01-speech-blstm.jl</code>脚本。如果您下载了这些文件，请确保已从数据文件夹中删除了<code class="highlighter-rouge">README.md</code>文件。
          </p>

          <blockquote>
            <p>$ julia 01-speech-blstm.jl</p>
          </blockquote>

          <p>这个网络在CPU上训练速度相当快，因此没有实现GPU功能。</p>

          <h1 id="get-the-code">获取源代码</h1>

          <p>
            此项目期间编写的代码可以在<a href="https://github.com/maetshju/gsoc2018">我的GitHub</a>上找到。还有几个请求是为了将代码贡献到更大的包生态系统中：
          </p>

          <ul>
            <li><a href="https://github.com/FluxML/Flux.jl/pull/306">在Flux的二元交叉熵损失中增加epsilon项</a></li>
            <li><a href="https://github.com/FluxML/Flux.jl/pull/342">将CTC损失添加到Flux</a></li>
            <li><a href="https://github.com/FluxML/model-zoo/pull/50">将framewise语音识别模型添加到Flux模型动物园</a></li>
          </ul>

          <h1 id="references">参考文献</h1>

          <p>Graves, A., & Schmidhuber, J. (2005). Framewise phoneme classification with bidirectional LSTM and other
            neural network architectures. <em>Neural Networks, 18</em>(5-6), 602-610.</p>

          <p>Graves, A., Fernández, S., Gomez, F., & Schmidhuber, J. (2006). Connectionist temporal classification:
            Labelling unsegmented sequence data with recurrent neural networks. In <em>Proceedings of the 23rd
              international conference on machine learning</em> (pp. 369-376). ACM.</p>

          <p>Zhang, Y., Pezeshki, M., Brakel, P., Zhang, S., Bengio, C. L. Y., & Courville, A. (2017). Towards
            end-to-end speech recognition with deep convolutional neural networks. <em>arXiv preprint arXiv:1701.02720</em>.</p>

        </div>
      </div>
    </div>
  </div>

  <br>

  <?php require_once('../_common/foot.html'); ?>
</body>

</html>